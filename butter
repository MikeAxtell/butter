#!/usr/bin/perl -w
use strict;
use Getopt::Long;
use File::Basename;

my $version_num = "0.3.3"; 
my $help_message = get_help($version_num);

# Moran Neuhof (neuhofmo) added on 12.9.2016: 
# In this version I replaced 2> with >& to work on CentOS 6.6

my $version;
my $help;
my $quiet;
my $mismatches = 0;
my $aln_cores = 1;
my $max_rep = 1000;
my $adapter;
my $no_condense;
my $ranmax = 3;
my $bam2wig = "combined";

# for use at the end
my $cl = join(" ", @ARGV);
$cl = "butter " . "$cl";

# If no arguments, quit with usage
unless($ARGV[-1]) {
    print "$help_message";
    exit;
}

# Get options
GetOptions ('version' => \$version,
	    'help' => \$help,
	    'quiet' => \$quiet,
	    'mismatches=i' => \$mismatches,
	    'aln_cores=i' => \$aln_cores,
	    'max_rep=i' => \$max_rep,
	    'adapter=s' => \$adapter,
	    'ranmax=i' => \$ranmax,
	    'bam2wig=s' => \$bam2wig,
            'no_condense' => \$no_condense);

# If version, print version_num and quit
if($version) {
    print "butter version $version_num\n";
    exit;
}

# If help, print help statement and quit
if($help) {
   print "$help_message";
   exit;
}

# Genome and Reads files must be specified and exist, or exit with usage
my $genome = pop @ARGV;
unless(-r $genome) {
    print "FATAL: No genome file found.\n$help_message";
    exit;
}

my $reads = pop @ARGV;
unless(-r $reads) {
    print "FATAL: No reads file found.\n$help_message";
    exit;
}


# Validate options
# mismatches must be an integer between 0 and 2
unless(($mismatches =~ /^\d+$/) and ($mismatches >= 0) and ($mismatches <= 1)) {
    print "FATAL: option --mismatches must be an integer between 0 and 1\n$help_message\n";
    exit;
}

# aln_cores must be an integer between 1 and 100
unless(($aln_cores =~ /^\d+$/) and ($aln_cores >= 1) and ($aln_cores <= 100)) {
    print "FATAL: option --aln_cores must be an integer between 1 and 100\n$help_message\n";
    exit;
}

# max_rep must be an integer of at least 6
unless(($max_rep =~ /^\d+$/) and ($max_rep >= 6)) {
    print "FATAL: option --max_rep must be an integer of at least 6.\n$help_message\n";
    exit;
}

# ranmax must be an integer of at leasr 1
unless(($ranmax =~ /^\d+$/) and ($ranmax >= 1)) {
    print "FATAL: option --ranmax must be an integer of at least 1.\n$help_message\n";
}

# If the adapter is specified, it must be ATGCatgc 8 or more
if($adapter) {
    unless($adapter =~ /^[ATGCatgc]{8,}$/) {
	print "FATAL: option --adapter must be a string of 8 or more ATGCatgc characters.\n$help_message\n";
	exit;
    }
}

# option --bam2wig must be combined, degradome, strandspec2, or none
unless(($bam2wig eq "combined") or
       ($bam2wig eq "degradome") or
       ($bam2wig eq "strandspec2") or
       ($bam2wig eq "none")) {
    print "FATAL: option --bam2wig must be either \'combined\', \'degradome\', \'strandspec2\', or \'none\'\n$help_message\n";
}

# Determine reads file type based on the extension, or die tryin
my $read_format;
my($reads_basename,$reads_dir,$reads_suffix) = fileparse($reads,qr/\.[^.]*/);
if(($reads_suffix eq ".fasta") or ($reads_suffix eq ".fa")) {
    $read_format = "f";
} elsif (($reads_suffix eq ".fastq") or ($reads_suffix eq ".fq")) {
    $read_format = "q";
} elsif ($reads_suffix eq ".csfasta") {
    $read_format = "C";
} else {
    print "FATAL: Could not determine format of reads file $reads .. extension must be .fa, .fasta, .fq, or .fastq\n$help_message\n";
    exit;
}
	 
# Final file name check .. no overwrites!
my $final_bam = $reads;
$final_bam =~ s/$reads_suffix/\.bam/g;
if(-e $final_bam) {
    print "FATAL: Alignment file $final_bam already exists and overwrites are not allowed. Rename, move, or delete the exisiting $final_bam file before alignment.\n$help_message\n";
    exit;
}

# Begin reporting to user
unless($quiet) {
    print STDERR "\nbutter version $version_num\n";
    print STDERR `date`;
    print STDERR "Host: ";
    print STDERR `hostname`;
    print STDERR "Working Directory: ";
    print STDERR `pwd`;
    print STDERR "Genome: $genome\n";
    print STDERR "Reads: $reads\n";
    print STDERR "Reads format: $read_format\n";
    print STDERR "Adapter: ";
    if($adapter) {
	print STDERR "$adapter\n";
    } else {
	print STDERR "None. Reads are assumed to be trimmed already.\n";
    }
    if($no_condense) {
	print STDERR "Read condensation: OFF\n";
    } else {
	print STDERR "Read condensation: ON\n";
    }
    print STDERR "Max Mismatches: $mismatches\n";
    print STDERR "Max number of possible placments for any read: $max_rep\n";
    print STDERR "Max number of possible placement for reads not guideable by density: $ranmax\n";
    print STDERR "Processor cores for bowtie: $aln_cores\n";
    print STDERR "bam2wig setting: $bam2wig\n";
    print STDERR "Checking dependencies\n";
}

# Dependency checks
my $c_query = "samtools";

my $samtools_check = check_install($c_query);
if($samtools_check) {
    unless($quiet) {
	print STDERR "\tsamtools: $samtools_check\n";
    }
} else {
    unless ($quiet) {
	print STDERR "\tsamtools: FAIL - ABORT because no samtools installation found\n";
    }
    exit;
}

$c_query = "bowtie";
my $bowtie_check = check_install($c_query);
if($bowtie_check) {
    unless($quiet) {
	print STDERR "\tbowtie: $bowtie_check\n";
    }
} else {
    unless ($quiet) {
	print STDERR "\tbowtie: FAIL - ABORT because no bowtie installation found\n";
    }
    exit;
}

my $bam2wig_check;
my $wigToBigWig_check;

unless($bam2wig eq "none") {
    $c_query = "bam2wig";
    $bam2wig_check = check_install($c_query);
    if($bam2wig_check) {
	unless($quiet) {
	    print STDERR "\tbam2wig: $bam2wig_check\n";
	}
	$c_query = "wigToBigWig";
	$wigToBigWig_check = check_install($c_query);
	if($wigToBigWig_check) {
	    unless($quiet) {
		print STDERR "\twigToBigWig: $wigToBigWig_check\n";
	    }
	} else {
	    unless($quiet) {
		print STDERR "\twigToBigWig: FAIL\! No wiggle to bigwig conversion will take place\n";
	    }
	}
    } else {
	unless($quiet) {
	    print STDERR "\tbam2wig: FAIL\! NO wiggle file will be produced\.\n";
	}
    }
}

# Check for indexed reference genome .. expect to find .1.ebwt, .2.ebwt, .3.ebwt, .4.ebwt, .rev.1.ebwt, .rev.2.ebwt
# If colorspace, expect to find .cs.1.ebwt, .cs.2.ebwt, .cs.3.ebwt, .cs.4.ebwt, .cs.rev.1.ebwt, .cs.rev.2.ebwt
my $bowtie_index_check = check_bowtie_index($genome,$read_format);
if($bowtie_index_check) {
    unless($quiet) {
	print STDERR "bowtie index files for genome $genome: Found\n";
    }
} else {
    unless($quiet) {
	print STDERR "bowtie index files for genome $genome: NOT FOUND .. attempting to build using bowtie-build ..";
    }
    $c_query = "bowtie-build";
    my $bb_check = check_install($c_query);
    if($bb_check) {
	if($read_format eq "C") {
	    my $c_genome_base = "$genome" . ".cs";
	    system "bowtie-build -C $genome $c_genome_base > /dev/null";
	} else {
	    system "bowtie-build $genome $genome > /dev/null";
	}
	$bowtie_index_check = check_bowtie_index($genome,$read_format);
	if($bowtie_index_check) {
	    unless($quiet) {
		print STDERR " Successful\n";
	    }
	} else {
	    unless($quiet) {
		print STDERR " FAILED - ABORTING\n";
	    }
	    exit;
	}
    } else {
	unless ($quiet) {
	    print STDERR " bowtie-build not installed. FATAL\n";
	}
	exit;
    }
}


# Perform 3' adapter trimming, if requested
my $trimmed;
if($adapter) {
    if($read_format eq "f") {
	$trimmed = trim_FA($reads,$adapter,$quiet);
    } elsif ($read_format eq "q") {
	$trimmed = trim_FQ($reads,$adapter,$quiet);
    } elsif ($read_format eq "C") {
	$trimmed = trim_CS($reads,$adapter,$quiet);
    }
} else {
    $trimmed = $reads;
}
unless (-r $trimmed) {
    die "FATAL: Expected file of trimmed reads $trimmed was not found\n";
}

# Compress trimmed reads to a non-redundant file, hashing duplicates
# If fastq, compressed is always written as a FASTA
# headers are re-named, arbitrarily to save memory

unless($quiet) {
    unless($no_condense) {
	print STDERR "Compressing trimmed reads to a set of non-redundant queries ..";
    }
}

my ($nr_trimmed_file,$read_count,$query_count) = get_nr_trimmed(\$trimmed,\$read_format,\$quiet,\$no_condense);
if(($read_format eq "q") and ($no_condense)) {
    # in this case, we have written a FASTA version of the file, but not condensed it.
    $trimmed = $nr_trimmed_file;
    $nr_trimmed_file = "NULL";
}

my $read_count_all = $read_count;

# bowtie call
unless($quiet) {
    print STDERR "Bowtie iteration one: $query_count queries representing $read_count reads\n";
}
my ($unmap_n,$unq_n,$mmap1_fasta_file) = call_bowtie_initial(\$genome,\$trimmed,\$nr_trimmed_file,\$read_format,\$quiet,\$aln_cores,\$mismatches,\$read_count,\$query_count);

# Get bin densities from the _unique_sorted.bam file
my %bin_dens = ();
my $base = $trimmed;
$base =~ s/\.[^\/]+$//g;
my $unq_sort_bam = "$base" . "_unique_sorted.bam";
my $unmapped_sort_bam = "$base" . "_unmapped_sorted.bam";
unless($quiet) {
    print STDERR "Gathering densities from uniquely placed reads ";
}

get_bin_dens(\$unq_sort_bam,\%bin_dens);
unless($quiet) {
    print STDERR "Done\n";
}

my $nr_base;
if($no_condense) {
    $nr_base = $reads;
} else {
    $nr_base = $nr_trimmed_file;
}
$nr_base =~ s/\.[^\/]+$//g;

# Place the 2 -mapped reads

unless($quiet) {
    print STDERR "Bowtie iteration two: $query_count queries representing $read_count reads\n";
}
my $max = 2;
my $r = 0;
my $p = 0;
my $m = 0;
my $o = 0;

my($two_bam,$two_m_bam,$mmap2_fasta_file) = call_bowtie_iterative(\$genome,\$base,\$quiet,\$no_condense,\$max,\$aln_cores,\$mismatches,\%bin_dens,\$mmap1_fasta_file,\$read_format,\$read_count,\$query_count,\$r,\$p,\$m,\$o,\$ranmax);

$m = 0;

unless(-r $two_bam) {
    die "FATAL: unknown failure .. expected file $two_bam not found\n";
}
#unless(-r $mmap2_fasta_file) {
#    die "FATAL: unknown failure .. expected file $mmap2_fasta_file not found\n";
#}

system "rm -f $two_m_bam";

# Update bin densities
unless($quiet) {
    print STDERR "Updating densities ";
}

get_bin_dens(\$two_bam,\%bin_dens);
unless($quiet) {
    print STDERR "Done\n";
}

# Place the 3-5 mapped reads
unless($quiet) {
    print STDERR "Bowtie iteration three: $query_count queries representing $read_count reads\n";
}
$max = 5;
my($five_bam,$five_m_bam,$mmap5_fasta_file) = call_bowtie_iterative(\$genome,\$base,\$quiet,\$no_condense,\$max,\$aln_cores,\$mismatches,\%bin_dens,\$mmap2_fasta_file,\$read_format,\$read_count,\$query_count,\$r,\$p,\$m,\$o,\$ranmax);

$m = 0;

unless(-r $five_bam) {
    die "FATAL: unknown failure .. expected file $five_bam not found\n";
}
#unless(-r $mmap5_fasta_file) {
#    die "FATAL: unknown failure .. expected file $mmap5_fasta_file not found\n";
#}

system "rm -f $five_m_bam";

# Update bin densities
unless($quiet) {
    print STDERR "Updating densities ";
}

get_bin_dens(\$five_bam,\%bin_dens);
unless($quiet) {
    print STDERR "Done\n";
}

# Place the >5 mapped reads
unless($quiet) {
    print STDERR "Bowtie iteration four: $query_count queries representing $read_count reads\n";
}

# 

$max = $max_rep;
my($max_bam,$real_m_bam,$mmapmax_fasta_file) = call_bowtie_iterative(\$genome,\$base,\$quiet,\$no_condense,\$max,\$aln_cores,\$mismatches,\%bin_dens,\$mmap5_fasta_file,\$read_format,\$read_count,\$query_count,\$r,\$p,\$m,\$o,\$ranmax);


unless(-r $max_bam) {
    die "FATAL: unknown failure .. expected file $max_bam not found\n";
}
unless(-r $real_m_bam) {
    die "FATAL: unknown failure .. expected file $real_m_bam not found\n";
}

system "rm -f $mmap1_fasta_file $mmap2_fasta_file $mmap5_fasta_file $mmapmax_fasta_file";

# Now, merge 
unless($quiet) {
    print STDERR "Merging to create final alignment";
}

# Write a final header file
my $final_header_file = "out_header.sam";
(open(OUTH, ">$final_header_file")) || die "Fatal: Failed to open header file for writing\n";
(open(INH, "samtools view -H $unq_sort_bam |")) || die "Fatal: Failed to open unq_sort_bam to modify header\n";
while (<INH>) {
    if($_ =~ /\tSO:/) {
	$_ =~ s/\tSO:\S+/\tSO:coordinate/g;
    }
    unless ($_ =~ /\@PG\t/) {
	print OUTH "$_";
    }
}
close INH;
print OUTH "\@PG\tID:butter\tVN:$version_num\tCL:\"$cl\"\n";
print OUTH "\@CO\tCustom tag XX:i: indicates number of valid placements for the read\n";
print OUTH "\@CO\tCustom tag XY:Z: indicates how the reported placement was selected.\n";
print OUTH "\@CO\tXY:Z:U indicates uniquely mapped read.\n";
print OUTH "\@CO\tXY:Z:P indicates multi-mapped and placed due to clustering.\n";
print OUTH "\@CO\tXY:Z:R indicates multi-mapped and randomly placed.\n";
print OUTH "\@CO\tXY:Z:N indicates unmapped because there were 0 valid alignment locations.\n";
print OUTH "\@CO\tXY:Z:M indicates unampped because it was a multi-mapped read where the number of valid alignment locations exceeded setting --max_rep.\n";
print OUTH "\@CO\tXY:Z:O indicates unmapped because it was a multi-mapped read which could not be placed by clustering, and whose number of valid alignment locations exceeded setting --ranmax.\n";
print OUTH "\@CO\tCustom tag XZ:f: indicates the probability as estimated by butter, of that read having come from the given location. Set to 1 for unmapped and uniquely mapped reads.\n";
print OUTH "\@CO\tOther custom tags from bowtie, see bowtie documentation\n";
close OUTH;


system "samtools merge -h $final_header_file $final_bam $unq_sort_bam $two_bam $five_bam $max_bam $unmapped_sort_bam $real_m_bam";
unless($quiet) {
    print STDERR " Done\n";
}

# clean up

system "rm -f $unq_sort_bam $two_bam $five_bam $max_bam $unmapped_sort_bam $final_header_file $real_m_bam";

# report
unless($quiet) {
    print STDERR "Summary of alignment file $final_bam",":\n";
    my $unmap_per = sprintf("%.1f", (100*($unmap_n / $read_count_all)));
    my $m_per = sprintf("%.1f", (100*($m / $read_count_all)));
    my $o_per = sprintf("%.1f", (100*($o / $read_count_all)));
    my $unplaced_sum = $unmap_n + $m + $o;
    my $unplaced_per = sprintf("%.1f", (100*($unplaced_sum / $read_count_all)));
    my $unq_per = sprintf("%.1f", (100*($unq_n / $read_count_all)));
    my $r_per = sprintf("%.1f", (100*($r / $read_count_all)));
    my $p_per = sprintf("%.1f", (100*($p / $read_count_all)));
    my $rp_sum = $r + $p;
    my $rp_per = sprintf("%.1f", (100*($rp_sum / $read_count_all)));
    print STDERR "Unampped reads: ";
    print STDERR "$unplaced_sum \/ $read_count_all \($unplaced_per\%\)\n";
    print STDERR "  Unmapped because 0 possible positions: ";
    print STDERR "$unmap_n \/ $read_count_all \($unmap_per\%\)\n";
    print STDERR "  Unmapped because more than $max_rep possible positions: ";
    print STDERR "$m \/ $read_count_all \($m_per\%\)\n";
    print STDERR "  Unmapped because placement random with more than $ranmax possible positions: ";
    print STDERR "$o \/ $read_count_all \($o_per\%\)\n";
    print STDERR "Uniquely mapped reads: ";
    print STDERR "$unq_n \/ $read_count_all \($unq_per\%\)\n";
    print STDERR "Multi-mapped reads: ";
    print STDERR "$rp_sum \/ $read_count_all \($rp_per\%\)\n";
    print STDERR "  Multi-mapped reads where placement was random:  ";
    print STDERR "$r \/ $read_count_all \($r_per\%\)\n";
    print STDERR "  Multi-mapped reads where placement was based on density: ";
    print STDERR "$p \/ $read_count_all \($p_per\%\)\n";
}

# index
print STDERR "\nIndexing alignment for you with samtools index ..";
system "samtools index $final_bam";
print STDERR " Done\n";


# generate wiggle(s) and bigwig(s) ..
if(($bam2wig ne "none") and ($bam2wig_check)) {
    print STDERR "\nCreating wiggle and possible bigwig file\(s\) with bam2wig\n";
    print STDERR "\nAppending bam2wig log information to bam2wig_log.txt\n";
    if($bam2wig eq "combined") {
	system "bam2wig $final_bam >>& bam2wig_log.txt";
    } elsif ($bam2wig eq "degradome") {
	system "bam2wig -s top -d $final_bam >>& bam2wig_log.txt";
	system "bam2wig -s bottom -d $final_bam >>& bam2wig_log.txt";
    } elsif ($bam2wig eq "strandspec2") {
	system "bam2wig -s top $final_bam >>& bam2wig_log.txt";
	system "bam2wig -s bottom $final_bam >>& bam2wig_log.txt";
    }
}

# too da loo
unless($quiet) {
    print STDERR "Completed at ";
    print STDERR `date`;
}
exit;


######
sub get_nr_trimmed {
    my($in,$format,$quiet,$no_condense) = @_; ## by reference .. string, string, string, string
    
    my $read_count = 0;
    my $query_count = 0;
    my $warning;
    (open(IN, "$$in")) || return 0;
    if($$no_condense) {
	# if this is a FASTQ file, will need to re-write as a FASTA file!
	if($$format eq "q") {
	    my $q2fa = $$in;
	    $q2fa =~ s/\.[^\/]+$/\.fasta/g;
	    (open(OUT, ">$q2fa")) || return 0;
	    my $head1;
	    my $seq1;
	    my $plus1;
	    my $qual1;
	    while (<IN>) {
		$head1 = $_;
		$head1 =~ s/^\@/>/;
		$seq1 = <IN>;
		$plus1 = <IN>;
		$qual1 = <IN>;
		if((length $seq1) < 15) {
		    ++$warning;
		} else {
		    ++$read_count;
		    ++$query_count;
		    print OUT "$head1","$seq1";
		}
	    }
	    close IN;
	    close OUT;
	    
	    if($warning) {
		print STDERR "\nWARNING\! $warning of your input reads were less than 15 nts in length. They were ignored\!\n";
	    }
	    
	    unless($$quiet) {
		print STDERR "\nFASTQ-formatted reads written in FASTA format to file $q2fa\n";
	    }
	    return ($q2fa,$read_count,$query_count);
	} else {
	    # If a fasta or csfasta input file, and no_condense is set, no modifications required
	    # but ya do need to count the queries
	    while (<IN>) {
		chomp;
		if($_ =~ /^>/) {
		    next;
		} else {
		    if((length $_) < 15) {
			++$warning;
		    } else {
			++$read_count;
			++$query_count;
		    }
		}
	    }
	    close IN;
	    if($warning) {
		print STDERR "\nWARNING\! $warning of your input reads were less than 15 nts in length. They were ignored\!\n";
		my $filt = $$in;
		if($$format eq "C") {
		    $filt =~ s/\.[^\/]+$/morethan15\.csfasta/g;
		} else {
		    $filt =~ s/\.[^\/]+$/morethan15\.fasta/g;
		}
		(open(IN, "$$in")) || return 0;
		(open(OUT, ">$filt")) || return 0;
		my $headrw;
		while (<IN>) {
		    chomp;
		    if($_ =~ /^>/) {
			$headrw = $_;
		    } elsif ((length $_) >= 15) {
			print OUT "$headrw\n$_\n";
		    }
		}
		close IN;
		close OUT;
		unless($$quiet) {
		    print STDERR "\nTotal reads: $read_count\n";
		}
		return ($filt,$read_count,$query_count);
	    } else {
		my $no_file = "NULL";
		unless($$quiet) {
		    print STDERR "\nTotal reads: $read_count\n";
		}
		return ($no_file,$read_count,$query_count);
	    }
	}
    } else {
	my $head;
	my $seq;
	my $plus;
	my $qual;
	my $val;
	my $reads_in = 0;
	my $nr_out = 0;
	my %temp_hash = ();
	while (<IN>) {
	    if($_ =~ /^\#/) {
		next;
	    }
	    if($$format eq "q") {
		$head = $_;
		$seq = <IN>;
		chomp $seq;
		$plus = <IN>;
		$qual = <IN>;
		if((length $seq) < 15) {
		    ++$warning;
		} else {
		    ++$temp_hash{$seq};
		    ++$reads_in;
		}
	    } else {
		$head = $_;
		$seq = <IN>;
		chomp $seq;
		if((length $seq) < 15) {
		    ++$warning;
		} else {
		    ++$temp_hash{$seq};
		    ++$reads_in;
		}
	    }
	}
	close IN;
	
	my $out = $$in;
	$out =~ s/\.[^\/]+$//g;  ## strip extension
	$out .= "_condensed";
	if ($$format eq "C") {
	    $out .= ".csfasta";
	} else {
	    $out .= ".fasta";
	}
	(open(OUT, ">$out")) || return 0;
	my @fields = ();
	my $junk;
	my $freq;
	my $base = $$in;
	$base =~ s/\.[^\/]+$//g; ## removes extension
	$base =~ s/^.*\///g; ## removes any leading path information
	
	while(($seq,$freq) = each %temp_hash) {
	    ++$nr_out;
	    print OUT ">$base", "_$nr_out", "_$freq\n";
	    print OUT "$seq\n";
	}
	close OUT;
	if($warning) {
	    print STDERR "\nWARNING\! $warning of your input reads were less than 15 nts in length. They were ignored\!\n";
	}
	
	unless($$quiet) {
	    print STDERR "\n\tReads in: $reads_in\n\tNon-redundant reads out: $nr_out\n";
	    print STDERR "\tFile: $out\n";
	}
	%temp_hash = (); ## attempt to clear memory
	
	return ($out,$reads_in,$nr_out);
    }
}


sub call_bowtie_iterative {
    my($genome,$base,$quiet,$no_condense,$max,$aln_cores,$mismatches,$bin_dens,$fasta_file,$read_format,$read_count,$query_count,$r,$p,$m,$o,$ranmax) = @_; ## passed by references .. all strings except the hash bin_dens
    
    # prepare the bowtie call
    my $bowtie_call;
    my $mmap_fasta_file = $$base;
    unless($$no_condense) {
	$mmap_fasta_file .= "_condensed";
    }
    $mmap_fasta_file .= "_mmap";
    $mmap_fasta_file .= "$$max";
    if($$read_format eq "C") {
	my $c_genome_base = "$$genome" . ".cs";
	$mmap_fasta_file .= ".csfasta";
	$bowtie_call = "bowtie -f -C -v $$mismatches --best --strata --all -m $$max --max $mmap_fasta_file --col-keepends -p $$aln_cores -S $c_genome_base $$fasta_file";
    } else {
	$mmap_fasta_file .= ".fasta";
	$bowtie_call = "bowtie -f -v $$mismatches --best --strata --all -m $$max --max $mmap_fasta_file -p $$aln_cores -S $$genome $$fasta_file";
    }
    unless($$quiet) {
	print STDERR "\tCalling bowtie with command:\n\t$bowtie_call\n";
	print STDERR "\tProgress \(dots indicate 1 percent of queries\):\n\t";
    }
    
    # progress counter
    my $queries_done = 0;
    my $queries_rpo = 0;
    my $queries_m = 0;
    my $dots_printed = 0;
    my $dots_should_be_printed = 0;
    my $r_at_start = $$r;
    my $p_at_start = $$p;
    my $m_at_start = $$m;
    my $o_at_start = $$o;
    
    # open output streams
    my $out_base = "$$base" . "$$max" . "_placed_sorted";
    my $m_out_base = "$$base" . "_exceeds$$max";
    (open(BAM, "| samtools view -S -b -u - >& /dev/null | samtools sort - $out_base >& /dev/null")) || return 0;
    (open(MBAM, "| samtools view -S -b -u - >& /dev/null | samtools sort - $m_out_base >& /dev/null")) || return 0;

    # open bowtie process
    (open(BOWTIE, "$bowtie_call >& /dev/null |")) || return 0;
    
    # begin parsing
    my $last_read = "NULL";
    my @fields = ();
    my @lines = ();
    my @scores = ();
    my $keep;
    my $score;
    my $line;

    while (<BOWTIE>) {
	if($_ =~ /^\@/) {
	    # header goes to both files
	    print BAM "$_";
	    print MBAM "$_";
	} else {
	    @fields = split ("\t", $_);
	    $line = $_;
	    if(($fields[0] ne $last_read) and
	       ($last_read ne "NULL")) {
		
		# process and output

		$keep = get_keepers(\@scores,\@lines,\$$r,\$$p,\$$m,\$last_read,\$$no_condense,\$$o,\$$ranmax);
		if($keep =~ /\tXY:Z:M/) {
		    print MBAM "$keep";
		    ++$queries_m;
		} else {
		    print BAM "$keep";
		    ++$queries_rpo;
		}
		
		# reset
		@lines = ();
		@scores = ();
		
		# progress
		++$queries_done;
		unless($$quiet) {
		    $dots_should_be_printed = int (100 * ($queries_done / $$query_count));
		    until ($dots_printed >= $dots_should_be_printed) {
			print STDERR ".";
			++$dots_printed;
		    }
		}
	    }
	    $score = score_line(\$line,\%$bin_dens);
	    push(@scores,$score);
	    push(@lines,$_);
	    $last_read = $fields[0];
	}
    }
    close BOWTIE;
    
    # process and output
    if($lines[0]) {
	$keep = get_keepers(\@scores,\@lines,\$$r,\$$p,\$$m,\$last_read,\$$no_condense,\$$o,\$$ranmax);
	if($keep =~ /\tXY:Z:M/) {
	    print MBAM "$keep";
	    ++$queries_m;
	} else {
	    print BAM "$keep";
	    ++$queries_rpo;
	}
    }
    
    close BAM;
    close MBAM;
    
    unless($$quiet) {
	print STDERR " Done\n";
    }
    
    # update
    $$read_count -= ($$r - $r_at_start);
    $$read_count -= ($$p - $p_at_start);
    $$read_count -= ($$o - $o_at_start);
    $$query_count -= $queries_rpo;
    
    my $bam = "$out_base" . ".bam";
    my $mbam = "$m_out_base" . ".bam";
    return ($bam,$mbam,$mmap_fasta_file);
}

sub score_line {
    my($line,$densities) = @_; ## passed by reference .. string, hash

    my $bin;
    my @fields = ();
    my $max = 0;
    my $this;
    my $key;
    @fields = split ("\t", $$line);
    $bin = int ($fields[3] / 50);
    for(my $i = $bin; $i > ($bin - 5); --$i) {
	$key = "$fields[2]" . ":" . "$i";
	if(exists($$densities{$key})) {
	    $this = $$densities{$key};
	} else {
	    $this = 0;
	}
	if($this > $max) {
	    $max = $this;
	}
    }
    return $max;
}

sub get_keepers {
    my($scores,$lines,$r,$p,$m,$read_name,$no_condense,$o,$ranmax) = @_; ## passed by reference .. array, array, rest strings
    my $best;
    my $best_score = 0;
    my $i = 0;
    my $output;
    my %i_to_score = ();
    my $total = 0;
    my $score;

    # parse read_name
    my $read_num;
    my $readbase;
    if($$no_condense) {
	$read_num = 1;
	$readbase = $$read_name;
    } elsif ($$read_name =~ /^(\S+)_(\d+)$/)  {
	$read_num = $2;
	$readbase = $1;
    }

    my $swapee;
    
    # First check if it is a -m violator ... it would be a single line, containing XM:i:[int] where [int] is a non-zero integer,
    if((scalar @$lines) == 1) {
	if($$lines[0] =~ /\tXM:i:(\d+)/) {
	    if($1 > 0) {
		++$$m;
		# Set XX:i to 0, and XY:Z to M, and XZ:f to 1
		$output = $$lines[0];
		$output =~ s/\n/\tXX:i:0\tXY:Z:M\tXZ:f:1\n/g;
		
		# increment to account for the one already written
		--$read_num;
		
		# add extra lines, if needed
		# loop cannot be entered if no_condense is set, as $read_num is always set to zero by this point
		for(my $j = $read_num; $j > 0; --$j) {
		    ++$$m;
		    $swapee = $$lines[0];
		    $swapee =~ s/\n/\tXX:i:0\tXY:Z:M\tXZ:f:1\n/g;
		    $swapee =~ s/^[^\t]+\t//g;  ## remove old read name
		    $swapee = "$readbase" . "_" . "$j\t" . "$swapee";
		    $output .= $swapee;
		}
		return $output;
	    } else {
		die "FATAL: in sub-routine get_keepers: received a line with XM:i: call of $1 ... \n";
	    }
	}
    }

    # hash them and count them
    foreach $score (@$scores) {
	$i_to_score{$i} = $score;
	$total += $score;
	++$i;
    }
    
    my @synonyms = ();
    my $syno;
    my $new_name;
    my $new_qual;

    my @swapee_fields = ();
    my $swapped;
    
    my $maybe;
    my $maybe_score;
    my $chance;
    
    
    my $xx_i = scalar(@$lines);
    my $XZf;
    my @of = ();
    if($total == 0) {
	# no guidance, randomly select, unless its a ranmax violator
	$XZf = sprintf("%.3f",1/(scalar(@$lines)));
	if($xx_i > $$ranmax) {
	    ++$$o;
	    @of = split ("\t", $$lines[0]);
	    $of[1] = 4;  ## set SAM FLAG to 4 for unmapped
	    $of[2] = "\*";
	    $of[3] = 0;
	    $of[4] = 0;
	    $of[5] = "\*";
	    $of[6] = "\*";
	    $of[7] = 0;
	    $of[8] = 0;
	    $output = join("\t", @of);
	    $output =~ s/\n/\tXX:i:$xx_i\tXY:Z:O\tXZ:f:1\n/g;  ## XZ:f set to 1 .. we are 100% certain that this was too random to attempt to place

	    # increment to account for the one already written
	    --$read_num;
	    
	    # add extra lines, if needed
	    # loop cannot be entered if no_condense is set, as $read_num is always set to zero by this point
	    for(my $j = $read_num; $j > 0; --$j) {
		++$$o;
		@of = split ("\t", $$lines[0]);
		$of[1] = 4;  ## set SAM FLAG to 4 for unmapped
		$of[2] = "\*";
		$of[3] = 0;
		$of[4] = 0;
		$of[5] = "\*";
		$of[6] = "\*";
		$of[7] = 0;
		$of[8] = 0;
		$swapee = join("\t", @of);
		$swapee =~ s/\n/\tXX:i:$xx_i\tXY:Z:O\tXZ:f:1\n/g;  ## XZ:f set to 1 .. we are 100% certain that this was too random to attempt to place
		$swapee =~ s/^[^\t]+\t//g;  ## remove old read name
		$swapee = "$readbase" . "_" . "$j\t" . "$swapee";
		$output .= $swapee;
	    }
	} else {
	    # no guidance, not a ranmax violator. randomly place
	    ++$$r;
	    $best = int(rand(scalar(@$lines)));
	    $output = $$lines[$best];
	    $output =~ s/\n/\tXX:i:$xx_i\tXY:Z:R\tXZ:f:$XZf\n/g;
	
	    # increment to account for the one already written
	    --$read_num;
	    
	    # add extra lines, if needed
	    # loop cannot be entered if no_condense is set, as $read_num is always set to zero by this point
	    for(my $j = $read_num; $j > 0; --$j) {
		++$$r;
		$best = int(rand(scalar(@$lines)));
		$swapee = $$lines[$best];
		$swapee =~ s/\n/\tXX:i:$xx_i\tXY:Z:R\tXZ:f:$XZf\n/g;
		$swapee =~ s/^[^\t]+\t//g;  ## remove old read name
		$swapee = "$readbase" . "_" . "$j\t" . "$swapee";
		
		# test
		#print STDERR "\tAt j of $j next line set as: $swapee";
		
		$output .= $swapee;
	    }
	}
	return $output;
    } else {
	# placement
	
	my @keys_perm = sort {$i_to_score{$b} <=> $i_to_score{$a}} keys %i_to_score;
	my @keys = @keys_perm;
	++$$p;
	my $keep;
	my $keep_ok;
	
	my $total_perm = $total;
	my $x;
	
	until($keep_ok) {
	    $maybe = shift @keys;
	    $maybe_score = $i_to_score{$maybe};
	    $chance = $maybe_score / $total;
	    $XZf = sprintf("%.3f",($maybe_score / $total_perm));
	    if($chance == 1) {
		$keep = $maybe;
		$keep_ok = 1;
	    } else {
		$x = rand();
		if($x <= $chance) {
		    $keep = $maybe;
		    $keep_ok = 1;
		}
	    }
	    $total -= $maybe_score;
	}
	$output = $$lines[$keep];
	$output =~ s/\n/\tXX:i:$xx_i\tXY:Z:P\tXZ:f:$XZf\n/g;
	

	## add more lines, if needed
	# increment to account for the one already written
	--$read_num;
	
	# add extra lines, if needed
	# loop cannot be entered if no_condense is set, read_num will always be zero by this point
	for(my $j = $read_num; $j > 0; --$j) {
	    ++$$p;
	    @keys = @keys_perm;
	    $keep = '';
	    $keep_ok = '';
	    $total = $total_perm;

	    until($keep_ok) {
		$maybe = shift @keys;
		$maybe_score = $i_to_score{$maybe};
		$chance = $maybe_score / $total;
		$XZf = sprintf("%.3f",($maybe_score / $total_perm));
		if($chance == 1) {
		    $keep = $maybe;
		    $keep_ok = 1;
		} else {
		    $x = rand();
		    if($x <= $chance) {
			$keep = $maybe;
			$keep_ok = 1;
		    }
		}
		$total -= $maybe_score;
	    }
	    $swapee = $$lines[$keep];
	    $swapee =~ s/\n/\tXX:i:$xx_i\tXY:Z:P\tXZ:f:$XZf\n/g;
	    $swapee =~ s/^[^\t]+\t//g;  ## remove old read name
	    $swapee = "$readbase" . "_" . "$j\t" . "$swapee";
	    $output .= $swapee;
	}
	return $output;
    }
}
	
    
sub get_bin_dens {
    my($bam,$bin_dens) = @_;  ## by reference. string, hash
    (open(DEPTH, "samtools depth $$bam |")) || return 0;
    my @fields = ();
    my @bins = ();
    my $key;
    while (<DEPTH>) {
	chomp;
	@fields = split ("\t", $_);
	@bins = what_bins($fields[1]);
	foreach my $bin (@bins) {
	    $key = "$fields[0]" . ":" . "$bin";
	    $$bin_dens{$key} += $fields[-1];
	}
    }
    close DEPTH;
    
    # test
    #my @keys = sort(keys(%bin_dens));
    #foreach my $k (@keys) {
#	print "$k\t$bin_dens{$k}\n";
  #  }
   # exit;
}

sub what_bins {
    my ($loc) = @_;
    my $bin = int ($loc / 50);
    my @bins = ();
    if($bin >= 0) {
	push(@bins, $bin);
    }
    for(my $i = 1; $i < 5; ++$i) {
	--$bin;
	if($bin >= 0) {
	    push(@bins, $bin);
	}
    }
    return @bins;
}
    

sub call_bowtie_initial {
    my($genome,$orig_reads,$reads,$read_format,$quiet,$cores,$v,$read_count,$query_count) = @_; ## passed by reference ..all strings 

    my $bowtie_call;
    my $mmap_fasta_file;
    if($$read_format eq "C") {
	my $c_genome_base = "$$genome" . ".cs";
	if($$reads eq "NULL") {  
	    ## in other words, no_condense, so use the original trimmed reads for alignment
	    $mmap_fasta_file = $$orig_reads;
	    $mmap_fasta_file =~ s/\.[^\.]+$/_mmap1\.csfasta/g;
	    $bowtie_call = "bowtie -f -C -v $$v --best --strata --all -m 1 --max $mmap_fasta_file --col-keepends -p $$cores -S $c_genome_base $$orig_reads";
	} else { 
	    $mmap_fasta_file = $$reads;
	    $mmap_fasta_file =~ s/\.[^\.]+$/_mmap1\.csfasta/g;
	    $bowtie_call = "bowtie -f -C -v $$v --best --strata --all -m 1 --max $mmap_fasta_file --col-keepends -p $$cores -S $c_genome_base $$reads";
	}
    } else {
	if($$reads eq "NULL") {
	    ## no_condense is active
	    $mmap_fasta_file = $$orig_reads;
	    $mmap_fasta_file =~ s/\.[^\.]+$/_mmap1\.fasta/g;
	    $bowtie_call = "bowtie -f -v $$v --best --strata --all -m 1 --max $mmap_fasta_file -p $$cores -S $$genome $$orig_reads";
	} else {
	    $mmap_fasta_file = $$reads;
	    $mmap_fasta_file =~ s/\.[^\.]+$/_mmap1\.fasta/g;
	    $bowtie_call = "bowtie -f -v $$v --best --strata --all -m 1 --max $mmap_fasta_file -p $$cores -S $$genome $$reads";  ## always -f because of read condensation process
	}
    }
    unless($$quiet) {
	print STDERR "\tCalling bowtie with command:\n\t$bowtie_call\n";
	print STDERR "\tProgress \(dots indicate one percent of queries\):\n\t";
    }
    # progress counter
    my $dots_done = 0;
    my $dots_should_be_done = 0;
    
    # strip the extension
    my $base;
    if($$reads eq "NULL") {
	$base = $$orig_reads;
    } else {
	$base = $$reads;
    }
    $base =~ s/\.[^\/]+$//g;
    my $orig_base = $$orig_reads;
    $orig_base =~ s/\.[^\/]+$//g;
    
    # open output streams
    my $unmapped = "$orig_base" . "_unmapped_sorted";
    (open(UNMAPPED, "| samtools view -S -b -u - >& /dev/null | samtools sort - $unmapped >& /dev/null")) || return 0;
    my $unique_bam_prefix = "$orig_base" . "_unique_sorted";
    (open(UNIQUE, "| samtools view -S -b -u - >& /dev/null | samtools sort - $unique_bam_prefix >& /dev/null")) || return 0;
    
    # Counters
    my $unmap_nr = 0;
    my $unq_nr = 0;
    my $mmap_nr = 0;
    my $unmap_n = 0;
    my $unq_n = 0;
    my $mmap_n = 0;
    
    my $query_n = 0;
    
    # open bowtie stream
    (open(BOWTIE, "$bowtie_call >& /dev/null |")) || return 0;
    
    # parse
    my $last_read = "NULL";
    my $this_read;
    my $this_flag;
    my $aln_count = 0;
    my $string;
    
    my $count;
    my $readbase;
    
    while (<BOWTIE>) {
	# headers go to every output stream
	if($_ =~ /^@/) {
	    print UNMAPPED "$_";
	    print UNIQUE "$_";
	} else {
	    if($_ =~ /^([^\t]+)\t(\d+)\t/) {
		$this_read = $1;
		$this_flag = $2;
	    } else {
		die "\nFATAL: Failed to determine read name and flag rom SAM line $_";
	    }
	    if(($this_read ne $last_read) and
	       ($last_read ne "NULL")) {

		# progress bar as percentage of queries
		unless($$quiet) {
		    ++$query_n;
		    $dots_should_be_done = int (100 * ($query_n / $$query_count));
		    until ($dots_done >= $dots_should_be_done) {
			print STDERR ".";
			++$dots_done;
		    }
		}

		process_string(\$string,\$aln_count);  ## adds XX:i to all, and XY:Z to unmapped and unique mapped
		
		if($aln_count == 0) {
		    
		    ## could be either XM:i:0, for truly unmapped, or something else, for a -m violator.
		    if($string =~ /\tXM:i:0\D/) {
			# truly unmapped, report to the UNMAPPED output stream
			# add XZ:f custom tag, set to 1 (we are 100% sure it is unmapped)
			$string =~ s/\n/\tXZ:f:1\n/;
			++$unmap_n;
			++$unmap_nr;
			print UNMAPPED "$string";
		    
			# expand if necessary
			unless($$reads eq "NULL") {
			    if ($last_read =~ /^(\S+)_(\d+)$/) {
				$readbase = $1;
				$count = $2;
			    } else {
				die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
			    }
			    --$count;  ## increments for the one already written
			    for(my $j = $count; $j > 0; --$j) {
				$string =~ s/^[^\t]+\t//g;
				$string = "$readbase" . "_" . "$j\t" . "$string";
				print UNMAPPED "$string";
				++$unmap_n;
			    }
			}
		    } else {
			# suppress .. violated -m  ... just count em for reporting
			# no need to add XZ custom tag, these are being suppressed
			++$mmap_n;
			++$mmap_nr;
			# expand if necessary
			unless($$reads eq "NULL") {
			    if ($last_read =~ /^(\S+)_(\d+)$/) {
				$readbase = $1;
				$count = $2;
			    } else {
				die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
			    }
			    --$count;  ## increments for the one already written
			    for(my $j = $count; $j > 0; --$j) {
				++$mmap_n;
			    }
			}
		    }
		} elsif ($aln_count == 1) {
		    ## add XZ custom tag, set to 1 (we are 100% sure these are unique mappers)
		    $string =~ s/\n/\tXZ:f:1\n/;
		    print UNIQUE "$string";
		    ++$unq_n;
		    ++$unq_nr;
		    # expand if necessary
		    unless($$reads eq "NULL") {
			if ($last_read =~ /^(\S+)_(\d+)$/) {
			    $readbase = $1;
			    $count = $2;
			} else {
			    die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
			}
			--$count;  ## increments for the one already written
			for(my $j = $count; $j > 0; --$j) {
			    $string =~ s/^[^\t]+\t//g;
			    $string = "$readbase" . "_" . "$j\t" . "$string";
			    print UNIQUE "$string";
			    ++$unq_n;
			}
		    }
		}
		
		# clear
		$string = '';
		$aln_count = 0;
	    }
	    $string .= $_;
	    unless($this_flag & 4) {
		++$aln_count;
	    }
	    $last_read = $this_read;
	}
    }
    # Last read
    
    process_string(\$string,\$aln_count);  ## adds XX:i to all, and XY:Z to unmapped and unique mapped
    if($aln_count == 0) {
	
	## could be either XM:i:0, for truly unmapped, or something else, for a -m violator.
	if($string =~ /\tXM:i:0\D/) {
	    # truly unmapped, report to the UNMAPPED output stream
	    # add XZ:f custom tag, set to 1 (we are 100% sure it is unmapped)
	    $string =~ s/\n/\tXZ:f:1\n/;
	    ++$unmap_n;
	    ++$unmap_nr;
	    print UNMAPPED "$string";
	    
	    # expand if necessary
	    unless($$reads eq "NULL") {
		if ($last_read =~ /^(\S+)_(\d+)$/) {
		    $readbase = $1;
		    $count = $2;
		} else {
		    die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
		}
		--$count;  ## increments for the one already written
		for(my $j = $count; $j > 0; --$j) {
		    $string =~ s/^[^\t]+\t//g;
		    $string = "$readbase" . "_" . "$j\t" . "$string";
		    print UNMAPPED "$string";
		    ++$unmap_n;
		}
	    }
	} else {
	    # suppress .. violated -m  ... just count em for reporting
	    # no need to add XZ custom tag, these are being suppressed
	    ++$mmap_n;
	    ++$mmap_nr;
	    # expand if necessary
	    unless($$reads eq "NULL") {
		if ($last_read =~ /^(\S+)_(\d+)$/) {
		    $readbase = $1;
		    $count = $2;
		} else {
		    die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
		}
		--$count;  ## increments for the one already written
		for(my $j = $count; $j > 0; --$j) {
		    ++$mmap_n;
		}
	    }
	}
    } elsif ($aln_count == 1) {
	## add XZ custom tag, set to 1 (we are 100% sure these are unique mappers)
	$string =~ s/\n/\tXZ:f:1\n/;
	print UNIQUE "$string";
	++$unq_n;
	++$unq_nr;
	# expand if necessary
	unless($$reads eq "NULL") {
	    if ($last_read =~ /^(\S+)_(\d+)$/) {
		$readbase = $1;
		$count = $2;
	    } else {
		die "FATAL in sub-routine call_bowtie_initial .. failed to parse count from read name $last_read\n";
	    }
	    --$count;  ## increments for the one already written
	    for(my $j = $count; $j > 0; --$j) {
		$string =~ s/^[^\t]+\t//g;
		$string = "$readbase" . "_" . "$j\t" . "$string";
		print UNIQUE "$string";
		++$unq_n;
	    }
	}
    }
    
    close BOWTIE;
    close UNMAPPED;
    close UNIQUE;
    
    # Verify presence of the --max file .. or not. 
    #unless(-r $mmap_fasta_file) {
	#die "FATAL in sub-routine call_bowtie_initial ... after bowtie run, expected --max file $mmap_fasta_file not readable\n";
    #}
    
    # update ....
    $$read_count -= $unmap_n;
    $$read_count -= $unq_n;
    $$query_count -= $unmap_nr;
    $$query_count -= $unq_nr;
    
    
    
    unless($$quiet) {
	print STDERR " Done\n";
    }
    return ($unmap_n,$unq_n,$mmap_fasta_file);
}

sub process_string {
    my($input,$x) = @_; ## by reference
    my $tag = "\tXX:i:$$x";
    if($$x == 0) {
	$tag .= "\tXY:Z:N\n"; ## N means unmapped
    } elsif ($$x == 1) {
	$tag .= "\tXY:Z:U\n"; ## U means uniquely placed
    } else {
	$tag .= "\n";
    }
    $$input =~ s/\n/$tag/g;
}
    
sub check_bowtie_index {
    my ($genome,$read_format) = @_;
    if(($read_format eq "f") or ($read_format eq "q")) {
	my $one = "$genome" . ".1.ebwt";
	my $two = "$genome" . ".2.ebwt";
	my $three = "$genome" . ".3.ebwt";
	my $four = "$genome" . ".4.ebwt";
	my $rev1 = "$genome" . ".rev.1.ebwt";
	my $rev2 = "$genome" . ".rev.2.ebwt";
	if ((-r $one) and
	    (-r $two) and
	    (-r $three) and
	    (-r $four) and
	    (-r $rev1) and
	    (-r $rev2)) {
	    return 1;
	} else {
	    return 0;
	}
    } elsif ($read_format eq "C") {
	my $one = "$genome" . ".cs.1.ebwt";
	my $two = "$genome" . ".cs.2.ebwt";
	my $three = "$genome" . ".cs.3.ebwt";
	my $four = "$genome" . ".cs.4.ebwt";
	my $rev1 = "$genome" . ".cs.rev.1.ebwt";
	my $rev2 = "$genome" . ".cs.rev.2.ebwt";
	if ((-r $one) and
	    (-r $two) and
	    (-r $three) and
	    (-r $four) and
	    (-r $rev1) and
	    (-r $rev2)) {
	    return 1;
	} else {
	    return 0;
	}
    }
}

sub check_install {
    my ($query) = @_;
    (open(CHECK, "which $query |")) || return 0;
    my $check = <CHECK>;
    close CHECK;
    chomp $check;
    return $check;
}

sub get_help {
    my ($version_num) = @_;
    my $help = "
butter: Bowtie UTilizing iTerative placEment of Repetitive small rnas
version $version_num

USAGE: butter [options] [reads.fa\/.fasta\/.fq\/.fastq\/.csfasta] [genome.fa]

DEPENDENCIES:
   samtools
   bowtie

OPTIONAL DEPENDENCIES:
   bam2wig
   wigToBigig

OPTIONS:
   --version : print version and quit
   --help: print this message and quit
   --quiet: suppress progress and error reporting
   --no_condense: Do not condense to a non-redundant set of sequences for bowtie. Preserves original read names, but is much slower.
   --mismatches [integer]: Number of mismatches allowed for a valid alignment. Default 0. Must be either 0 or 1.
   --aln_cores [integer]: Number of processor cores to use during bowtie alignment phase. Default 1. Must be integer 1-100.
   --max_rep [integer]: Maximum number of possible alignments. Reads with more than this number of possible placements are not retained in the final alignment. Default 1000. Must be integer >=6.
   --ranmax [integer]: For multi-mapped reads that can't be placed based on density, suppress random placement if the number of choices exceeds ranmax. Default 3. Must be integer >= 1. Note that setting of one means NO such reads will be placed.
   --adapter [string]: 3' Adapter sequence to trim. Must be 8 or more ATGCatgc characters. If specified, 3' adpater trimming is enabled.
   --bam2wig [string]: Create wiggle and possibly bigwig file from the final BAM alignment. Either \'combined\', \'degradome\', \'strandspec2\', or \'none\'. Deafults to combined.

DOCUMENTATION:
   type \'perldoc butter\'

";
    return $help;
}

sub trim_FA {
    my($untrimmed,$adapter,$quiet) = @_;
    unless($quiet) {
	print STDERR "\nPerforming 3' adapter trimming of file $reads with adapter $adapter ... ";
    }

    (open(IN, "$untrimmed")) || return 0;
    my $trimmedFA = "$untrimmed";
    $trimmedFA =~ s/\.[^\/]+$//g;  ## strip any extension
    $trimmedFA .= "_trimmed.fasta"; ## add new extension
    (open(OUT, ">$trimmedFA")) || return 0;
    my $header;
    my $trim_len;
    my $no_insert = 0; ## includes adapter-only and no-adapter cases
    my $too_short = 0;
    my $amb = 0;
    my $ok;
    my $trim_seq;
    while (<IN>) {
	# skip lines devoid of anything but a newline
	if($_ =~ /^\n$/) {
	    next;
	}
	# skip lines devoid of anything at all
	if($_ =~ /^$/) {
	    next;
	}
	chomp;
	if($_ =~ /^\#/) {
	    next;
	} elsif($_ =~ /^>/) {
	    $header = $_;
	} else {
	    $trim_len = 0;
	    while ($_ =~ /$adapter/ig) {
		$trim_len = (pos $_) - (length $adapter);
	    }
	    if($trim_len == 0) {
		++$no_insert;
	    } elsif ($trim_len < 15) {
		++$too_short;
	    } else {
		$trim_seq = substr($_,0,$trim_len);
		if($trim_seq =~ /[^ATGCatcg]/) {
		    ++$amb;
		} else {
		    ++$ok;
		    print OUT "$header\n$trim_seq\n";
		}
	    }
	}
    }
    close IN;
    close OUT;
    unless($quiet) {
	print STDERR " Done\n";
	print STDERR "\tNo insert \(includes adapter-only and no-adapter cases combined\): $no_insert\n";
	print STDERR "\tToo short \(less than 15nts\): $too_short\n";
	print STDERR "\tAmbiguous bases after trimming: $amb\n";
	print STDERR "\tOK - output: $ok\n";
	print STDERR "\tResults in file $trimmedFA\n";
    }
    return $trimmedFA;
}

sub trim_FQ {
    my($untrimmed,$adapter,$quiet) = @_;
    unless($quiet) {
	print STDERR "\nPerforming 3' adapter trimming of file $reads with adapter $adapter ... ";
    }
    (open(IN, "$untrimmed")) || return 0;
    my $trimmedFQ = "$untrimmed";
    $trimmedFQ =~ s/\.[^\/]+$//g; ## strip extension
    $trimmedFQ .= "_trimmed.fastq"; ## add new extension
    (open(OUT, ">$trimmedFQ")) || return 0;
    my $header;
    my $trim_len;
    my $no_insert = 0; ## includes adapter-only and no-adapter cases
    my $too_short = 0;
    my $amb = 0;
    my $ok;
    my $trim_seq;
    my $plus;
    my $seq;
    my $qual;
    my $trim_qual;
    while (<IN>) {
	# skip lines devoid of anything but a newline
	if($_ =~ /^\n$/) {
	    next;
	}
	# skip lines devoid of anything at all
	if($_ =~ /^$/) {
	    next;
	}
	chomp;
	$header = $_;
	$seq = <IN>;
	chomp $seq;
	$plus = <IN>;
	chomp $plus;
	$qual = <IN>;
	chomp $qual;
	
	# crude validation
	unless(($header =~ /^\@/) and
	       ($plus =~ /^\+/)) {
	    print STDERR "\nFATAL: FASTQ format parse error in sub-routine trim_FQ\n";
	    exit;
	}
	$trim_len = 0;
	while ($seq =~ /$adapter/ig) {
	    $trim_len = (pos $seq) - (length $adapter);
	}
	if($trim_len == 0) {
	    ++$no_insert;
	} elsif ($trim_len < 15) {
	    ++$too_short;
	} else {
	    $trim_seq = substr($seq,0,$trim_len);
	    if($trim_seq =~ /[^ATGCatcg]/) {
		++$amb;
	    } else {
		++$ok;
		$trim_qual = substr($qual,0,$trim_len);
		print OUT "$header\n$trim_seq\n$plus\n$trim_qual\n";
	    }
	}
    }
    
    close IN;
    close OUT;
    unless($quiet) {
	print STDERR " Done\n";
	print STDERR "\tNo insert \(includes adapter-only and no-adapter cases combined\): $no_insert\n";
	print STDERR "\tToo short \(less than 15nts\): $too_short\n";
	print STDERR "\tAmbiguous bases after trimming: $amb\n";
	print STDERR "\tOK - output: $ok\n";
	print STDERR "\tResults in file $trimmedFQ\n";
    }

    return $trimmedFQ;
}

sub trim_CS {
    my($untrimmed,$adapter,$quiet) = @_;
    
    my $cs_used_adapter = adapter2cs($adapter);
    
    unless($quiet) {
	print STDERR "\nAdapter trimming file $untrimmed with adapter $adapter (translated to $cs_used_adapter) ...";
    }
    
    (open(IN, "$untrimmed")) || return 0;
    my $trimmedCS = "$untrimmed";
    $trimmedCS =~ s/\.[^\/]+$//g;  #### s/\..*$//g;  ## strip any extension
    $trimmedCS .= "_trimmed.csfasta"; ## add new extension
    (open(OUT, ">$trimmedCS")) || return 0;
	
    my $header;
    my $trim_len;
    my $no_insert = 0; ## includes adapter-only and no-adapter cases
    my $too_short = 0;
    my $amb = 0;
    my $ok;
    my $trim_seq;
    my $cs_l_num = 0;

    while (<IN>) {
	# skip lines devoid of anything but a newline
	if($_ =~ /^\n$/) {
	    next;
	}
	# skip lines devoid of anything at all
	if($_ =~ /^$/) {
	    next;
	}
	chomp;
	++$cs_l_num;
	if($_ =~ /^\#/) {
	    next;
	}
	if($_ =~ /^>/) {
	    $header = $_;
	} else {
	    $trim_len = 0;
	    while ($_ =~ /$cs_used_adapter/ig) {
		$trim_len = (pos $_) - (length $cs_used_adapter) - 1; # subtract 1 to remove the hybrid color .. leading T is still included, so sRNA length is trim_len - 1
	    }
	    if($trim_len <= 1) {  ## 1 is no insert for colorspace .. leading T still there
		++$no_insert;
	    } elsif (($trim_len - 1) < 15) {  ## accounts for leading T (or other base key)
		++$too_short;
	    } else {
		$trim_seq = substr($_,0,$trim_len);  ## because of above, this also chops the hybrid color
		if($trim_seq =~ /^[ATGC][0123]+$/) {
		    ++$ok;
		    print OUT "$header\n$trim_seq\n";
		} else {
		    ++$amb;
		}
	    }
	}
    }
    close IN;
    close OUT;
    
    unless($quiet) {
	print STDERR " Done\n";
	print STDERR "\tNo insert \(includes adapter-only and no-adapter cases combined\): $no_insert\n";
	print STDERR "\tToo short \(less than 15nts\): $too_short\n";
	print STDERR "\tAmbiguous bases after trimming: $amb\n";
	print STDERR "\tOK - output: $ok\n";
	print STDERR "\tResults in file $trimmedCS\n";
    }
    
    return $trimmedCS;
}

sub adapter2cs {
    my($base_adapter) = @_;
    $base_adapter = uc $base_adapter;
    unless($base_adapter =~ /^[ATGC]+$/) {
        print STDERR "\nFATAL: Invlaid adapter $base_adapter found in sub-routine adapter2cs\n";
	exit;
    }
    my %colors = (
        'AA' => 0,
        'CC' => 0,
        'GG' => 0,
        'TT' => 0,
        'AC' => 1,
        'CA' => 1,
        'GT' => 1,
        'TG' => 1,
        'AG' => 2,
        'CT' => 2,
        'GA' => 2,
        'TC' => 2,
        'AT' => 3,
        'CG' => 3,
        'GC' => 3,
        'TA' => 3,
        );
    my $dibase;
    my $color_adapter;
    my @letters = split('', $base_adapter);
    for(my $i = 0; $i <= ((scalar @letters) - 2); ++$i) {
        $dibase = "$letters[$i]" . "$letters[($i + 1)]";
        unless(exists($colors{$dibase})) {
            print STDERR "\nFATAL: Failure to lookup the dibase $dibase in sub-routine adapter2cs\n";
            exit;
	}
        $color_adapter .= $colors{$dibase};
    }
    return $color_adapter;
}

 __END__

=head1 SYNOPSIS

butter: Bowtie UTilizing iTerative placEment of Repetitive small rnas

A wrapper for bowtie to produce small RNA-seq alignments where multimapped small RNAs tend to be placed near regions of confidently high density.

=head1 LICENSE

Copyright (C) 2014 Michael J. Axtell                                                             
                                                                                                 
This program is free software: you can redistribute it and/or modify                             
it under the terms of the GNU General Public License as published by                             
the Free Software Foundation, either version 3 of the License, or                                
(at your option) any later version.                                                              
                                                                                                 
This program is distributed in the hope that it will be useful,                                  
    but WITHOUT ANY WARRANTY; without even the implied warranty of                                   
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                                    
GNU General Public License for more details.                                                     
                                                                                                 
You should have received a copy of the GNU General Public License                                
along with this program.  If not, see <http://www.gnu.org/licenses/>.


=head1 CITATION

A preprint describing butter has been deposited at http://biorxiv.org/

Butter: High-precision genomic alignment of small RNA-seq data. Michael J Axtell bioRxiv doi: http://dx.doi.org/10.1101/007427

The manuscript is also, as of this writing (Sep 9, 2014), being prepared for submission to a peer-reviewed journal.

=head1 AUTHOR

Michael J. Axtell, Penn State University, mja18@psu.edu

=head1 DEPENDENCIES

perl (version 5; <www.perl.org>) .. installed at /usr/bin/perl

samtools <http://samtools.sourceforge.net/> .. installed to your PATH

bowtie <http://bowtie-bio.sourceforge.net/index.shtml> .. installed to your PATH

=head1 OPTIONAL DEPENDENCIES

bam2wig <https://github.com/MikeAxtell/bam2wig>  .. installed to your PATH. Not required to run butter but is required to make wiggle files from the BAM alignment. bam2wig is also included with the butter download.

wigToBigWig <http://genome.ucsc.edu/goldenPath/help/bigWig.html> .. installed to your PATH. Not required to run butter but is required to make bigwig files from wiggle files.

=head1 INSTALL

Install dependencies (see above), and then place the butter script in your PATH

=head1 USAGE

butter [options] [reads.fa/.fasta/.fq/.fastq] [genome.fa]

=head1 OPTIONS

--version: print version and quit

--help: print usage and option information, then quit

--quiet: suppress progress reports

--no_condense: do not condense trimmed reads into non-redundant sequences for bowtie mapping. Preserves original read names, but is (much) slower.

--mismatches [integer]: Number of mismatches allowed for a valid alignment. Default 0. Must be either 0 or 1.

--aln_cores [integer]: Number of processor cores to use during bowtie alignment phase. Default 1. Must be integer 1-00.

--max_rep [integer]: Maximum number of possible placements for a multi-mapped read being guided by density. Such reads with a number of placements more than --max_rep will be reported as unmapped and have custom tag XY:Z set to M. Default: 1000. Must be integer of at least 6.

--ranmax [integer]: Maximum number of possible placements for a multi-mapped read that can't be guided by density. Such reads with a number of placements more than --ranmax will be reported as unmapped and have custom tag XY:Z set to O. Default: 3. Must be integer of 1 or more.

--adapter [string]: 3' Adapter sequence to trim. Must be 8 or more ATGCatgc characters. If specified, 3' adapter trimming is enabled.

--bam2wig [string]: Options for generating wiggle and bigwig coverage file(s) from the final BAM alignment. Can be 'combined', 'degradome', 'strandspec2', or 'none'. Defaults to 'combined'. Combined merges coverage on both strands to a single positive value. Degradome creates two separate tracks for the plus and minus strands, each tallying just the coverage at 5' ends. strandspec2 creates two files, one for each strand, tallying total coverage. None creates no wiggle/bigwig files. 

=head1 INPUT FILES

=head2 Small RNA-seq data

Files must be in FASTA, FASTQ, or colorspace-fasta format. File extensions must be used to indicate the format. .fasta and .fa are acceptable for FASTA files. .fastq and .fq are accetpable for colorspace files. .csfasta must be used for color-space files. There is no support for paired-end reads.

Colorspace data are assumed to conform to colorspace-FASTA specifications (beginning with a nucleotide, followed by a string of colors [0,1,2,3] or ambiguity codes [.]. If trimmed colorspace data are provided, it is assumed that the 'hybrid' color at the 3' end has been removed. If colorspace data are trimmed by butter, the hybrid color at the 3' end will be removed (see below).

=head2 Reference genome

File must be in FASTA format. Chromosome names will be truncated after the first white-space encountered.

butter will search for the expected bowtie indices in the same directory as the genome file. If the input format is FASTQ or FASTA, butter will expect the bowtie indices to have the form [your_genome].[ebwt], where 'your_genome' is the name of your genome file, and [ebwt] represents the six distinct file extensions for bowtie genome index files. If your input data is colorspace, butter will expect the genome indices to have the form [your_genome].cs.[ebwt] instead. The .cs serves as a reminder that the indices are built in colorspace.  If the expected bowtie indices are not found, butter will attempt to use bowtie-build under default parameters to build them.

=head1 METHODS

=head2 Adapter trimming - FASTA

For each read, the 3'-most exact match to the supplied adapter sequence (via option --adapter) is found and trimmed off. Trimmed data shorter than 15nts are suppressed from output. In addition, reads with non ATGCatgc characters after trimming are also suppressed. Comment lines in the original file are ignored, and will not be output to the trimmed file.

=head2 Adapter trimming - FASTQ

Identical to trimming for FASTA data, with the addition of trimming the quality values to the same length as the trimmed sequence data.

=head2 Adapter trimming - Colorspace-FASTA

The input --adapter sequence is converted to colorspace. Then, for each read, the 3'-most exact match to the color-string is found. Trimming takes off the matched color string, as well as the ambiguous color left at the end .. this is the hybrid color formed by the di-base created by the last nucleotide of the small RNA and the first nt of the adapter. When mapped using bowtie with the --col-keepends option, this trimming results in the alignment of the full length small RNA.

=head2 Read Condensation

For the purpose of bowtie mapping, the trimmed reads are condensed such that each unique small RNA sequence is represented only once. In the process, the reads are re-named. Condensaiton can save considerable CPU time, and the re-naming of the reads saves substantial memory (because each read name does not have to be stored by the script for later output). The condensed reads are written in FASTA or .csfasta format (e.g. the quality values from FASTQ files are ignored). This is justified because the bowtie alignment parameters being used ignore quality values.

The condensed reads are written to a file in the working directory with the name [your_reads]_condensed.(cs)fasta.

The condensed read names follow a simple system. Consider an example read name:

>my_reads_758883_12

The '758883' indicates that this is unique sequence number 758883 (arbitrarily ordered). The '12' indicates that there were 12 reads in the input file with this sequence.

The option --no_condense turns off read condensation, so the original read names are preserved. This option is much slower. If option --no_condense is used for an input file in FASTQ format, a FASTA version of the reads will be written to disk.

=head2 Alignments and placements

Four iterations of bowtie are called successively on the reads after adapter trimming (if applicable) and condensation (if applicable) and conversion from FASTQ to FASTA format (if applicable, see above).

The first iteration uses bowtie setting -m 1 to limit alignments to reads with only one unique possible position in the reference genome. This output stream is parsed to retain unmapped reads, and reads with unique alignments. Using bowtie's --max option, reads with more than 1 possible alignment are written to a temporary FASTA or csFASTA file.

After this, the densities of the uniquely placed reads are tallied, genome-wide, using a sliding window of 250 nts, and a step size of 50 nts. The density in each window is simply the sum of all of the read-depths at each nt in the window (e.g., 'area under curve').

The second bowtie iteration uses the multi-mapped reads set aside in the first iteration for a run with bowtie -m set to 2. Thus, only reads with 2 possible placements are output.  After calculating the densities, both possible placements for each read that had 2 possible locations are analyzed. Each location falls into 5 different windows .. the window with the maximum score is taken as the existing density of each placement. In cases where all possible placements have an exisiting density of zero, the choice of which placement to retain is simply random. If one possible placement has existing density and the other doesn't, the retained placement will be that which is next to existing density. If both possible placements have existing density, the retained placement will be selected based on probabilities dictated by the relative density abundances among the two choices. For example, if placement one had a maximum density score of 70, and and placement two had a maximum density score of 30, the probability of placement one being retained is 70 / (70 + 30) [e.g. 70%] and the probability of placement two being retained is 30 / (70 + 30) [e.g. 30%]. As in the first iteration, reads with multi-mappings higher than the -m set point are written to a temporary FASTA or csFASTA file for analysis in the next iteration.

After the process is repeated for two more iterations .. the densities are updated with the new data, and multi-mapped reads that remain are re-mapped iteratively. Iteration three captures reads with 3-5 possible placements, and iteration four captures reads with between 5 and --max_rep number of placements (default is 1000).

=head2 De-condensation

Unless run with option --no_condense, reads must be de-condensed. This occurs while writing sorted BAM files, the non-redundant queries are de-condensed, such that there is an alignment line for each copy of that sequence present in the input data.  For instance, with our example read from above (my_reads_758883_12), there were 12 copies. So, somewhere in the output BAM file there will be twelve reads .. my_reads_758883_12, my_reads_758883_11, my_reads_758883_10 ... all the way down to my_reads_758883_1.

Note that, for reads with more than 1 potential placement, each de-condensed read is considered separately. Because placement of multi-mapped reads can be either random or probabilistic (see above 'Placement'), this means that not all copies of an identical sequence will necessarily be placed at the same location.

=head2 Merging

After all iterations of placements and density calculations have completed, the resulting sorted bam files are merged to a single final bam alignment, and the intermediate bam files deleted.

=head2 Temporary files

butter writes a number of temporary files to disk during a run .. intermediate BAM files, and temporary FASTA (or csFASTA) files. These will all be deleted at the completetion of the run.

=head1 OUTPUT

The output is a single BAM alignment file sorted by chromosomal position. The BAM header includes lines describing the run. butter adds three custom tags for each alignment. All reads are in the alignment file, including reads that were unmapped (unmapped reads have bit 0x4 set in the SAM FLAG field, per SAM specification). Other custom tags not described below are from bowtie .. see bowtie documentation for their meaning.

Custom tag XX:i: indicates number of valid placements for the read (of which only one is being shown)

Custom tag XY:Z: indicates how the reported placement was selected. U: uniquely mapped, P: multi-mapped and placed due to clustering, R: multi-mapped and randomly placed, N: unmapped, M: Multi-mappings exceeded setting --max_rep, so no placement performed, O: multi-mapped with no density-based placement possible, number of locations exceeded setting --ranmax, so no placement performed.

Custom tag XZ:f: indicates the probability that the given read came from the reported position, based on the butter iterative density analysis. Set to 1 for reads with XY:Z: of M, U, N, and O.

=head2 Wiggle and bigwig files

Depending on setting of option --bam2wig and the availability of the bam2wig and wigToBigWig programs, butter will also create wiggle and bigwig coverage files for easier use on a genome browser.

=cut
